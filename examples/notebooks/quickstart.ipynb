{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Frame Extractor - Quickstart Guide\n",
    "\n",
    "This notebook demonstrates how to use the YouTube Frame Extractor package to extract and analyze frames from YouTube videos using different methods.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The YouTube Frame Extractor offers two main approaches:\n",
    "\n",
    "1. **Browser-based extraction**: Uses Selenium to capture frames directly from the YouTube player\n",
    "2. **Download-based extraction**: Downloads videos using yt-dlp and extracts frames\n",
    "\n",
    "Both methods can be enhanced with Vision Language Models (VLMs) for intelligent frame selection based on natural language descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's make sure we have the package installed and set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add the parent directory to the path for importing the package\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Move up two directories from the current notebook location\n",
    "project_root = Path().absolute().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Verify we can import the package\n",
    "try:\n",
    "    from src.youtube_frame_extractor.extractors.browser import BrowserExtractor\n",
    "    from src.youtube_frame_extractor.extractors.download import DownloadExtractor\n",
    "    from src.youtube_frame_extractor.analysis.vlm import VLMAnalyzer\n",
    "    print(\"✅ Successfully imported YouTube Frame Extractor package\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importing package: {str(e)}\")\n",
    "    print(\"Please make sure you're running this notebook from the examples/notebooks directory\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Set up logging to display in the notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Create output directory for extracted frames\n",
    "output_dir = Path(\"./notebook_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Output will be saved to: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for Display\n",
    "\n",
    "Let's define some helper functions to display extracted frames in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_frames(frames, max_frames=6, figsize=(15, 10), title=\"Extracted Frames\"):\n",
    "    \"\"\"Display a grid of extracted frames.\"\"\"\n",
    "    num_frames = min(max_frames, len(frames))\n",
    "    if num_frames == 0:\n",
    "        print(\"No frames to display\")\n",
    "        return\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    cols = min(3, num_frames)\n",
    "    rows = (num_frames + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        \n",
    "        # Get the frame image\n",
    "        if 'frame' in frames[i] and frames[i]['frame'] is not None:\n",
    "            # If frame is already a PIL image or numpy array\n",
    "            img = frames[i]['frame']\n",
    "        elif 'path' in frames[i] and os.path.exists(frames[i]['path']):\n",
    "            # If we have a path to the image file\n",
    "            img = Image.open(frames[i]['path'])\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, \"Image not available\", ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy array if it's a PIL image\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        \n",
    "        # Add frame info as subtitle\n",
    "        subtitle = f\"Frame {i+1}\"\n",
    "        if 'time' in frames[i]:\n",
    "            subtitle += f\" | Time: {frames[i]['time']:.2f}s\"\n",
    "        if 'similarity' in frames[i]:\n",
    "            subtitle += f\" | Score: {frames[i]['similarity']:.2f}\"\n",
    "        \n",
    "        plt.title(subtitle)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "def display_video_info(video_id):\n",
    "    \"\"\"Display YouTube video embed and basic info.\"\"\"\n",
    "    embed_html = f\"\"\"\n",
    "    <div style=\"width:560px;\">\n",
    "        <h3>YouTube Video: {video_id}</h3>\n",
    "        <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/{video_id}\" \n",
    "                frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; \n",
    "                gyroscope; picture-in-picture\" allowfullscreen>\n",
    "        </iframe>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(embed_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Browser-Based Frame Extraction\n",
    "\n",
    "Let's start with browser-based extraction, which captures frames directly from the YouTube player without downloading the full video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a YouTube video to extract frames from\n",
    "# We'll use the classic \"Never Gonna Give You Up\" as it's widely available\n",
    "video_id = \"dQw4w9WgXcQ\"\n",
    "\n",
    "# Display the video for reference\n",
    "display_video_info(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a browser extractor\n",
    "browser_extractor = BrowserExtractor(\n",
    "    output_dir=str(output_dir / \"browser\"),\n",
    "    headless=True  # Run browser in headless mode\n",
    ")\n",
    "\n",
    "# Extract frames\n",
    "try:\n",
    "    # Extract 5 frames, one every 3 seconds\n",
    "    frames = browser_extractor.extract_frames(\n",
    "        video_id=video_id,\n",
    "        interval=3.0,  # Capture a frame every 3 seconds\n",
    "        max_frames=5   # Extract 5 frames total\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully extracted {len(frames)} frames\")\n",
    "    \n",
    "    # Display the extracted frames\n",
    "    display_frames(frames, title=\"Browser-Extracted Frames\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error extracting frames: {str(e)}\")\n",
    "    print(\"\\nNote: Browser-based extraction requires Chrome/Chromium to be installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download-Based Frame Extraction\n",
    "\n",
    "Now let's try the download-based approach, which downloads the video and extracts frames locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a download extractor\n",
    "download_extractor = DownloadExtractor(\n",
    "    output_dir=str(output_dir / \"download\")\n",
    ")\n",
    "\n",
    "# Extract frames\n",
    "try:\n",
    "    # Extract frames at 0.25 fps (one frame every 4 seconds)\n",
    "    frames = download_extractor.extract_frames(\n",
    "        video_id=video_id,\n",
    "        frame_rate=0.25,  # Frames per second\n",
    "        max_frames=5      # Maximum number of frames\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully extracted {len(frames)} frames\")\n",
    "    \n",
    "    # Display the extracted frames\n",
    "    display_frames(frames, title=\"Download-Extracted Frames\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error extracting frames: {str(e)}\")\n",
    "    print(\"\\nNote: Download-based extraction requires ffmpeg to be installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VLM-Based Intelligent Frame Analysis\n",
    "\n",
    "Now let's use a Vision Language Model (VLM) to find frames that match a specific description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize VLM analyzer\n",
    "try:\n",
    "    vlm_analyzer = VLMAnalyzer(model_name=\"openai/clip-vit-base-patch16\")\n",
    "    print(\"✅ VLM analyzer initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing VLM analyzer: {str(e)}\")\n",
    "    print(\"Skipping VLM-based analysis\")\n",
    "    vlm_analyzer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Only proceed if VLM analyzer is available\n",
    "if vlm_analyzer is not None:\n",
    "    # Define a search query\n",
    "    search_query = \"person singing into microphone\"\n",
    "    \n",
    "    # Use the browser extractor with VLM analysis\n",
    "    try:\n",
    "        # Scan video for frames matching the query\n",
    "        matched_frames = browser_extractor.scan_video_for_frames(\n",
    "            video_id=video_id,\n",
    "            search_query=search_query,\n",
    "            vlm_analyzer=vlm_analyzer,\n",
    "            interval=2.0,     # Check every 2 seconds\n",
    "            threshold=0.25,   # Similarity threshold\n",
    "            max_frames=10     # Check up to 10 frames\n",
    "        )\n",
    "        \n",
    "        print(f\"Found {len(matched_frames)} frames matching the query: '{search_query}'\")\n",
    "        \n",
    "        # Sort by similarity score (highest first)\n",
    "        matched_frames.sort(key=lambda x: x.get('similarity', 0), reverse=True)\n",
    "        \n",
    "        # Display the matched frames\n",
    "        display_frames(matched_frames, title=f\"Frames Matching: '{search_query}'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in VLM analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Frame Processing and Analysis\n",
    "\n",
    "Let's demonstrate how to process the extracted frames with custom analysis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def detect_faces(image):\n",
    "    \"\"\"Detect faces in an image using OpenCV.\"\"\"\n",
    "    # Convert PIL Image to OpenCV format if needed\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Load the face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Convert to grayscale for face detection\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    \n",
    "    return faces, image\n",
    "\n",
    "def draw_faces_on_image(image, faces):\n",
    "    \"\"\"Draw rectangles around detected faces.\"\"\"\n",
    "    # Convert OpenCV image to PIL for drawing\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw rectangles around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        draw.rectangle(\n",
    "            [(x, y), (x + w, y + h)],\n",
    "            outline=\"red\",\n",
    "            width=3\n",
    "        )\n",
    "        draw.text((x, y - 10), \"Face\", fill=\"red\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "def process_frames_with_face_detection(frames):\n",
    "    \"\"\"Process frames to detect and highlight faces.\"\"\"\n",
    "    processed_frames = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        # Get the image\n",
    "        if 'frame' in frame and frame['frame'] is not None:\n",
    "            image = frame['frame']\n",
    "        elif 'path' in frame and os.path.exists(frame['path']):\n",
    "            image = Image.open(frame['path'])\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Detect faces\n",
    "        faces, cv_image = detect_faces(image)\n",
    "        \n",
    "        # Draw faces on the image\n",
    "        processed_image = draw_faces_on_image(cv_image, faces)\n",
    "        \n",
    "        # Create a new frame dict with the processed image\n",
    "        processed_frame = frame.copy()\n",
    "        processed_frame['frame'] = processed_image\n",
    "        processed_frame['faces_detected'] = len(faces)\n",
    "        \n",
    "        processed_frames.append(processed_frame)\n",
    "    \n",
    "    return processed_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if we have frames to process\n",
    "try:\n",
    "    if 'frames' in locals() and frames:\n",
    "        # Process frames with face detection\n",
    "        processed_frames = process_frames_with_face_detection(frames)\n",
    "        \n",
    "        # Display processed frames\n",
    "        display_frames(processed_frames, title=\"Frames with Face Detection\")\n",
    "        \n",
    "        # Show summary of face detection\n",
    "        face_counts = [frame.get('faces_detected', 0) for frame in processed_frames]\n",
    "        total_faces = sum(face_counts)\n",
    "        frames_with_faces = sum(1 for count in face_counts if count > 0)\n",
    "        \n",
    "        print(f\"Detected {total_faces} faces in {frames_with_faces} frames\")\n",
    "    else:\n",
    "        print(\"No frames available for processing\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing frames: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving Processed Results\n",
    "\n",
    "Finally, let's see how to save processed frames and metadata for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def save_processed_results(frames, video_id, output_path):\n",
    "    \"\"\"Save processed frames and metadata.\"\"\"\n",
    "    # Create results directory\n",
    "    results_dir = Path(output_path) / \"results\"\n",
    "    results_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Create a unique timestamp for this run\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create a results metadata file\n",
    "    metadata = {\n",
    "        \"video_id\": video_id,\n",
    "        \"extraction_time\": timestamp,\n",
    "        \"frame_count\": len(frames),\n",
    "        \"frames\": []\n",
    "    }\n",
    "    \n",
    "    # Process each frame\n",
    "    for i, frame in enumerate(frames):\n",
    "        # Create a unique filename for this frame\n",
    "        frame_filename = f\"{video_id}_{timestamp}_{i:03d}.jpg\"\n",
    "        frame_path = results_dir / frame_filename\n",
    "        \n",
    "        # Get the image\n",
    "        if 'frame' in frame and frame['frame'] is not None:\n",
    "            image = frame['frame']\n",
    "        elif 'path' in frame and os.path.exists(frame['path']):\n",
    "            image = Image.open(frame['path'])\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # Ensure image is a PIL Image\n",
    "        if not isinstance(image, Image.Image):\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        # Save the image\n",
    "        image.save(frame_path)\n",
    "        \n",
    "        # Add metadata\n",
    "        frame_meta = {\n",
    "            \"filename\": frame_filename,\n",
    "            \"path\": str(frame_path),\n",
    "            \"index\": i\n",
    "        }\n",
    "        \n",
    "        # Add additional metadata\n",
    "        for key, value in frame.items():\n",
    "            if key not in ['frame', 'path'] and not callable(value):\n",
    "                # Convert numpy types to native Python types for JSON serialization\n",
    "                if hasattr(value, 'item'):\n",
    "                    value = value.item()\n",
    "                frame_meta[key] = value\n",
    "        \n",
    "        metadata[\"frames\"].append(frame_meta)\n",
    "    \n",
    "    # Save the metadata\n",
    "    metadata_path = results_dir / f\"{video_id}_{timestamp}_metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    return str(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if we have processed frames to save\n",
    "try:\n",
    "    if 'processed_frames' in locals() and processed_frames:\n",
    "        # Save processed results\n",
    "        metadata_path = save_processed_results(\n",
    "            frames=processed_frames,\n",
    "            video_id=video_id,\n",
    "            output_path=output_dir\n",
    "        )\n",
    "        \n",
    "        print(f\"Saved processed results to: {metadata_path}\")\n",
    "        \n",
    "        # Display the metadata\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            print(\"\\nMetadata summary:\")\n",
    "            print(f\"- Video ID: {metadata['video_id']}\")\n",
    "            print(f\"- Extraction time: {metadata['extraction_time']}\")\n",
    "            print(f\"- Frame count: {metadata['frame_count']}\")\n",
    "            print(f\"- First frame: {metadata['frames'][0]['filename']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying metadata: {str(e)}\")\n",
    "    else:\n",
    "        print(\"No processed frames available to save\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup\n",
    "\n",
    "Finally, let's clean up any resources and show a summary of what we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean up resources\n",
    "try:\n",
    "    # Close the browser extractor if it's open\n",
    "    if 'browser_extractor' in locals() and browser_extractor._driver is not None:\n",
    "        browser_extractor._driver.quit()\n",
    "        print(\"Browser extractor cleaned up\")\n",
    "    \n",
    "    # Clear any large variables\n",
    "    for var in ['frames', 'matched_frames', 'processed_frames']:\n",
    "        if var in locals():\n",
    "            locals()[var] = None\n",
    "    \n",
    "    print(\"Cleanup complete\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during cleanup: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this quickstart guide, you've learned how to:\n",
    "\n",
    "1. **Set up** the YouTube Frame Extractor package\n",
    "2. **Extract frames** using browser-based and download-based methods\n",
    "3. **Analyze frames** with a Vision Language Model (VLM) to find content matching specific descriptions\n",
    "4. **Process frames** with custom analysis (face detection)\n",
    "5. **Save results** for later use\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try extracting frames from different videos\n",
    "- Experiment with different search queries for VLM analysis\n",
    "- Implement custom frame processing for your specific needs\n",
    "- Check out the Advanced Analysis notebook for more complex examples\n",
    "\n",
    "For more details on API usage and advanced features, refer to the documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}