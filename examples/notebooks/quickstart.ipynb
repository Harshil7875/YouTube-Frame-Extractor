{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# YouTube Frame Extractor - Quickstart Guide\n",
       "\n",
       "This notebook demonstrates how to use the YouTube Frame Extractor package to extract and analyze frames from YouTube videos using different methods.\n",
       "\n",
       "## Overview\n",
       "\n",
       "The YouTube Frame Extractor offers two main approaches:\n",
       "\n",
       "1. **Browser-based extraction**: Uses Selenium to capture frames directly from the YouTube player.\n",
       "2. **Download-based extraction**: Downloads videos using yt-dlp and extracts frames.\n",
       "\n",
       "Both methods can be enhanced with Vision Language Models (VLMs) for intelligent frame selection based on natural language descriptions."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Setup and Installation\n",
       "\n",
       "First, let's make sure we have the package installed and set up the environment:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Add the parent directory to the path for importing the package\n",
       "import sys\n",
       "import os\n",
       "from pathlib import Path\n",
       "\n",
       "# Move up two directories from the current notebook location\n",
       "project_root = Path().absolute().parent.parent\n",
       "sys.path.insert(0, str(project_root))\n",
       "\n",
       "# Verify we can import the package\n",
       "try:\n",
       "    from src.youtube_frame_extractor.extractors.browser import BrowserExtractor\n",
       "    from src.youtube_frame_extractor.extractors.download import DownloadExtractor\n",
       "    from src.youtube_frame_extractor.analysis.vlm import VLMAnalyzer\n",
       "    print(\"✅ Successfully imported YouTube Frame Extractor package\")\n",
       "except ImportError as e:\n",
       "    print(f\"❌ Error importing package: {str(e)}\")\n",
       "    print(\"Please make sure you're running this notebook from the examples/notebooks directory\")\n",
       "    raise"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Configure logging\n",
       "import logging\n",
       "import warnings\n",
       "\n",
       "# Set up logging to display in the notebook\n",
       "logging.basicConfig(\n",
       "    level=logging.INFO,\n",
       "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
       ")\n",
       "\n",
       "# Suppress unnecessary warnings\n",
       "warnings.filterwarnings('ignore', category=UserWarning)\n",
       "\n",
       "# Create output directory for extracted frames\n",
       "output_dir = Path(\"./notebook_output\")\n",
       "output_dir.mkdir(exist_ok=True)\n",
       "\n",
       "print(f\"Output will be saved to: {output_dir.absolute()}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Helper Functions for Display\n",
       "\n",
       "Let's define some helper functions to display extracted frames in the notebook:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import matplotlib.pyplot as plt\n",
       "from PIL import Image\n",
       "import numpy as np\n",
       "from IPython.display import display, HTML\n",
       "\n",
       "def display_frames(frames, max_frames=6, figsize=(15, 10), title=\"Extracted Frames\"):\n",
       "    \"\"\"Display a grid of extracted frames.\"\"\"\n",
       "    num_frames = min(max_frames, len(frames))\n",
       "    if num_frames == 0:\n",
       "        print(\"No frames to display\")\n",
       "        return\n",
       "    \n",
       "    # Calculate grid dimensions\n",
       "    cols = min(3, num_frames)\n",
       "    rows = (num_frames + cols - 1) // cols\n",
       "    \n",
       "    plt.figure(figsize=figsize)\n",
       "    plt.suptitle(title, fontsize=16)\n",
       "    \n",
       "    for i in range(num_frames):\n",
       "        plt.subplot(rows, cols, i + 1)\n",
       "        \n",
       "        # Get the frame image\n",
       "        if 'frame' in frames[i] and frames[i]['frame'] is not None:\n",
       "            img = frames[i]['frame']\n",
       "        elif 'path' in frames[i] and os.path.exists(frames[i]['path']):\n",
       "            img = Image.open(frames[i]['path'])\n",
       "        else:\n",
       "            plt.text(0.5, 0.5, \"Image not available\", ha='center', va='center')\n",
       "            plt.axis('off')\n",
       "            continue\n",
       "        \n",
       "        if isinstance(img, Image.Image):\n",
       "            img = np.array(img)\n",
       "        \n",
       "        plt.imshow(img)\n",
       "        subtitle = f\"Frame {i+1}\"\n",
       "        if 'time' in frames[i]:\n",
       "            subtitle += f\" | Time: {frames[i]['time']:.2f}s\"\n",
       "        if 'similarity' in frames[i]:\n",
       "            subtitle += f\" | Score: {frames[i]['similarity']:.2f}\"\n",
       "        plt.title(subtitle)\n",
       "        plt.axis('off')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.subplots_adjust(top=0.9)\n",
       "    plt.show()\n",
       "\n",
       "def display_video_info(video_id):\n",
       "    \"\"\"Display YouTube video embed and basic info.\"\"\"\n",
       "    embed_html = f\"\"\"\n",
       "    <div style='width:560px;'>\n",
       "        <h3>YouTube Video: {video_id}</h3>\n",
       "        <iframe width='560' height='315' src='https://www.youtube.com/embed/{video_id}' \n",
       "                frameborder='0' allow='accelerometer; autoplay; clipboard-write; encrypted-media; \n",
       "                gyroscope; picture-in-picture' allowfullscreen>\n",
       "        </iframe>\n",
       "    </div>\n",
       "    \"\"\"\n",
       "    display(HTML(embed_html))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Browser-Based Frame Extraction\n",
       "\n",
       "Let's start with browser-based extraction, which captures frames directly from the YouTube player without downloading the full video."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Define a YouTube video to extract frames from\n",
       "video_id = \"dQw4w9WgXcQ\"\n",
       "\n",
       "# Display the video for reference\n",
       "display_video_info(video_id)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Create a browser extractor\n",
       "browser_extractor = BrowserExtractor(\n",
       "    output_dir=str(output_dir / \"browser\"),\n",
       "    headless=True\n",
       ")\n",
       "\n",
       "# Extract frames (e.g., 5 frames every 3 seconds)\n",
       "try:\n",
       "    frames = browser_extractor.extract_frames(\n",
       "        video_id=video_id,\n",
       "        interval=3.0,\n",
       "        max_frames=5\n",
       "    )\n",
       "    print(f\"Successfully extracted {len(frames)} frames\")\n",
       "    display_frames(frames, title=\"Browser-Extracted Frames\")\n",
       "except Exception as e:\n",
       "    print(f\"Error extracting frames: {str(e)}\")\n",
       "    print(\"Note: Browser-based extraction requires Chrome/Chromium to be installed\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Download-Based Frame Extraction\n",
       "\n",
       "Now let's try the download-based approach, which downloads the video and extracts frames locally."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Create a download extractor\n",
       "download_extractor = DownloadExtractor(\n",
       "    output_dir=str(output_dir / \"download\")\n",
       ")\n",
       "\n",
       "# Extract frames (e.g., 5 frames at 0.25 fps)\n",
       "try:\n",
       "    frames = download_extractor.extract_frames(\n",
       "        video_id=video_id,\n",
       "        frame_rate=0.25,\n",
       "        max_frames=5\n",
       "    )\n",
       "    print(f\"Successfully extracted {len(frames)} frames\")\n",
       "    display_frames(frames, title=\"Download-Extracted Frames\")\n",
       "except Exception as e:\n",
       "    print(f\"Error extracting frames: {str(e)}\")\n",
       "    print(\"Note: Download-based extraction requires ffmpeg to be installed\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. VLM-Based Intelligent Frame Analysis\n",
       "\n",
       "Now let's use a Vision Language Model (VLM) to find frames that match a specific description."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Initialize VLM analyzer\n",
       "try:\n",
       "    vlm_analyzer = VLMAnalyzer(model_name=\"openai/clip-vit-base-patch16\")\n",
       "    print(\"✅ VLM analyzer initialized successfully\")\n",
       "except Exception as e:\n",
       "    print(f\"❌ Error initializing VLM analyzer: {str(e)}\")\n",
       "    print(\"Skipping VLM-based analysis\")\n",
       "    vlm_analyzer = None"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Proceed with VLM analysis if available\n",
       "if vlm_analyzer is not None:\n",
       "    search_query = \"person singing into microphone\"\n",
       "    try:\n",
       "        matched_frames = browser_extractor.scan_video_for_frames(\n",
       "            video_id=video_id,\n",
       "            search_query=search_query,\n",
       "            vlm_analyzer=vlm_analyzer,\n",
       "            interval=2.0,\n",
       "            threshold=0.25,\n",
       "            max_frames=10\n",
       "        )\n",
       "        print(f\"Found {len(matched_frames)} frames matching the query: '{search_query}'\")\n",
       "        matched_frames.sort(key=lambda x: x.get('similarity', 0), reverse=True)\n",
       "        display_frames(matched_frames, title=f\"Frames Matching: '{search_query}'\")\n",
       "    except Exception as e:\n",
       "        print(f\"Error in VLM analysis: {str(e)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Custom Frame Processing and Analysis\n",
       "\n",
       "Let's demonstrate how to process the extracted frames with custom analysis functions (e.g., face detection)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import cv2\n",
       "from PIL import Image, ImageDraw\n",
       "import numpy as np\n",
       "\n",
       "def detect_faces(image):\n",
       "    \"\"\"Detect faces in an image using OpenCV.\"\"\"\n",
       "    if isinstance(image, Image.Image):\n",
       "        image = np.array(image)\n",
       "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
       "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
       "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
       "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
       "    return faces, image\n",
       "\n",
       "def draw_faces_on_image(image, faces):\n",
       "    if not isinstance(image, Image.Image):\n",
       "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
       "        image = Image.fromarray(image)\n",
       "    draw = ImageDraw.Draw(image)\n",
       "    for (x, y, w, h) in faces:\n",
       "        draw.rectangle([(x, y), (x+w, y+h)], outline=\"red\", width=3)\n",
       "        draw.text((x, y-10), \"Face\", fill=\"red\")\n",
       "    return image\n",
       "\n",
       "def process_frames_with_face_detection(frames):\n",
       "    processed_frames = []\n",
       "    for frame in frames:\n",
       "        if 'frame' in frame and frame['frame'] is not None:\n",
       "            image = frame['frame']\n",
       "        elif 'path' in frame and os.path.exists(frame['path']):\n",
       "            image = Image.open(frame['path'])\n",
       "        else:\n",
       "            continue\n",
       "        faces, cv_image = detect_faces(image)\n",
       "        processed_image = draw_faces_on_image(cv_image, faces)\n",
       "        processed_frame = frame.copy()\n",
       "        processed_frame['frame'] = processed_image\n",
       "        processed_frame['faces_detected'] = len(faces)\n",
       "        processed_frames.append(processed_frame)\n",
       "    return processed_frames"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# If frames are available, process them with face detection\n",
       "try:\n",
       "    if 'frames' in locals() and frames:\n",
       "        processed_frames = process_frames_with_face_detection(frames)\n",
       "        display_frames(processed_frames, title=\"Frames with Face Detection\")\n",
       "        face_counts = [frame.get('faces_detected', 0) for frame in processed_frames]\n",
       "        total_faces = sum(face_counts)\n",
       "        frames_with_faces = sum(1 for count in face_counts if count > 0)\n",
       "        print(f\"Detected {total_faces} faces in {frames_with_faces} frames\")\n",
       "    else:\n",
       "        print(\"No frames available for processing\")\n",
       "except Exception as e:\n",
       "    print(f\"Error processing frames: {str(e)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Saving Processed Results\n",
       "\n",
       "Finally, let's see how to save processed frames and metadata for later use."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import json\n",
       "import time\n",
       "\n",
       "def save_processed_results(frames, video_id, output_path):\n",
       "    \"\"\"Save processed frames and metadata.\"\"\"\n",
       "    results_dir = Path(output_path) / \"results\"\n",
       "    results_dir.mkdir(exist_ok=True, parents=True)\n",
       "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
       "    metadata = {\n",
       "        \"video_id\": video_id,\n",
       "        \"extraction_time\": timestamp,\n",
       "        \"frame_count\": len(frames),\n",
       "        \"frames\": []\n",
       "    }\n",
       "    for i, frame in enumerate(frames):\n",
       "        frame_filename = f\"{video_id}_{timestamp}_{i:03d}.jpg\"\n",
       "        frame_path = results_dir / frame_filename\n",
       "        if 'frame' in frame and frame['frame'] is not None:\n",
       "            image = frame['frame']\n",
       "        elif 'path' in frame and os.path.exists(frame['path']):\n",
       "            image = Image.open(frame['path'])\n",
       "        else:\n",
       "            continue\n",
       "        if not isinstance(image, Image.Image):\n",
       "            image = Image.fromarray(image)\n",
       "        image.save(frame_path)\n",
       "        frame_meta = {\n",
       "            \"filename\": frame_filename,\n",
       "            \"path\": str(frame_path),\n",
       "            \"index\": i\n",
       "        }\n",
       "        for key, value in frame.items():\n",
       "            if key not in ['frame', 'path'] and not callable(value):\n",
       "                if hasattr(value, 'item'):\n",
       "                    value = value.item()\n",
       "                frame_meta[key] = value\n",
       "        metadata[\"frames\"].append(frame_meta)\n",
       "    metadata_path = results_dir / f\"{video_id}_{timestamp}_metadata.json\"\n",
       "    with open(metadata_path, 'w') as f:\n",
       "        json.dump(metadata, f, indent=2)\n",
       "    return str(metadata_path)\n",
       "\n",
       "if 'processed_frames' in locals() and processed_frames:\n",
       "    metadata_path = save_processed_results(\n",
       "        frames=processed_frames,\n",
       "        video_id=video_id,\n",
       "        output_path=output_dir\n",
       "    )\n",
       "    print(f\"Saved processed results to: {metadata_path}\")\n",
       "    try:\n",
       "        with open(metadata_path, 'r') as f:\n",
       "            metadata = json.load(f)\n",
       "        print(\"\\nMetadata summary:\")\n",
       "        print(f\"- Video ID: {metadata['video_id']}\")\n",
       "        print(f\"- Extraction time: {metadata['extraction_time']}\")\n",
       "        print(f\"- Frame count: {metadata['frame_count']}\")\n",
       "        print(f\"- First frame: {metadata['frames'][0]['filename']}\")\n",
       "    except Exception as e:\n",
       "        print(f\"Error displaying metadata: {str(e)}\")\n",
       "else:\n",
       "    print(\"No processed frames available to save\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 8. Cleanup\n",
       "\n",
       "Finally, let's clean up any resources and show a summary of what we've learned."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Clean up resources\n",
       "try:\n",
       "    if 'browser_extractor' in locals() and browser_extractor._driver is not None:\n",
       "        browser_extractor._driver.quit()\n",
       "        print(\"Browser extractor cleaned up\")\n",
       "    for var in ['frames', 'matched_frames', 'processed_frames']:\n",
       "        if var in locals():\n",
       "            locals()[var] = None\n",
       "    print(\"Cleanup complete\")\n",
       "except Exception as e:\n",
       "    print(f\"Error during cleanup: {str(e)}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Summary\n",
       "\n",
       "In this quickstart guide, you've learned how to:\n",
       "1. **Set up** the YouTube Frame Extractor package\n",
       "2. **Extract frames** using browser-based and download-based methods\n",
       "3. **Analyze frames** with a Vision Language Model (VLM) to find content matching specific descriptions\n",
       "4. **Process frames** with custom analysis (face detection)\n",
       "5. **Save results** for later use\n",
       "\n",
       "### Next Steps\n",
       "- Try extracting frames from different videos\n",
       "- Experiment with different search queries for VLM analysis\n",
       "- Implement custom frame processing for your specific needs\n",
       "- Check out the Advanced Analysis notebook for more complex examples\n",
       "\n",
       "For more details on API usage and advanced features, refer to the documentation."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }   